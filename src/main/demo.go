package main

import (
	"6.824/mr"
	"fmt"
	"sort"
	"strings"
	"unicode"
)

func Map(document string, value string) (res []mr.KeyValue) {
	m := make(map[string]bool)
	words := strings.FieldsFunc(value, func(x rune) bool { return !unicode.IsLetter(x) })
	for _, w := range words {
		m[w] = true
	}
	for w := range m {
		kv := mr.KeyValue{w, document}
		res = append(res, kv)
	}
	return
}

// The reduce function is called once for each key generated by Map, with a
// list of that key's string value (merged across all inputs). The return value
// should be a single output value for that key.
func Reduce(key string, values []string) string {
	sort.Strings(values)
	return fmt.Sprintf("%d %s", len(values), strings.Join(values, ","))
}

//func Map(filename string, contents string) []mr.KeyValue {
//	// function to detect word separators.
//	ff := func(r rune) bool { return !unicode.IsLetter(r) }
//
//	// split contents into an array of words.
//	words := strings.FieldsFunc(contents, ff)
//
//	kva := []mr.KeyValue{}
//	for _, w := range words {
//		kv := mr.KeyValue{w, "1"}
//		kva = append(kva, kv)
//	}
//	return kva
//}
//
////
//// The reduce function is called once for each key generated by the
//// map tasks, with a list of all the values created for that key by
//// any map task.
////
//func Reduce(key string, values []string) string {
//	// return the number of occurrences of this word.
//	return strconv.Itoa(len(values))
//}

func main() {
	mapf, reducef := Map, Reduce
	m := mr.MakeCoordinator([]string{"main/pg-dorian_gray.txt", "main/pg-sherlock_holmes.txt",
		"main/pg-being_ernest.txt", "main/pg-frankenstein.txt", "main/pg-grimm.txt", "main/pg-huckleberry_finn.txt",
		"main/pg-metamorphosis.txt", "main/pg-tom_sawyer.txt"}, 8)
	go mr.Worker(mapf, reducef)
	go mr.Worker(mapf, reducef)

	for true {
		switch {
		case m.Done():
			fmt.Println("all complete")
			return
		}
	}
}
